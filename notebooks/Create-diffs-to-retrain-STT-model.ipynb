{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Read Watson Speech to Text transcript\n",
    "\n",
    "A transcript file, generated by Watson Speech to Text, for a sample product video is available here: [product_video.txt](https://raw.githubusercontent.com/spackows/CASCON-2021_Processing_video/main/sample-product-video/product_video.txt)\n",
    "\n",
    "In this step, download that transcript file to the notebook working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('product_video.txt', <http.client.HTTPMessage at 0x7f82901075e0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the file\n",
    "import urllib.request\n",
    "transcript_url = \"https://raw.githubusercontent.com/spackows/CASCON-2021_Processing_video/main/sample-product-video/product_video.txt\"\n",
    "transcript_filename = \"product_video.txt\"\n",
    "urllib.request.urlretrieve( transcript_url, transcript_filename )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_video.txt\r\n"
     ]
    }
   ],
   "source": [
    "# View the contents of the working directory\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Read corrected transcript\n",
    "\n",
    "A manually corrected transcript for the same product video is available here: [product_video_corrected.txt](https://raw.githubusercontent.com/spackows/CASCON-2021_Processing_video/main/sample-product-video/product_video_corrected.txt)\n",
    "\n",
    "In this step, download that corrected transcript file to the notebook working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('product_video_corrected.txt', <http.client.HTTPMessage at 0x7f8290107af0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the file\n",
    "import urllib.request\n",
    "corrected_url = \"https://raw.githubusercontent.com/spackows/CASCON-2021_Processing_video/main/sample-product-video/product_video_corrected.txt\"\n",
    "corrected_filename = \"product_video_corrected.txt\"\n",
    "urllib.request.urlretrieve( corrected_url, corrected_filename )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_video_corrected.txt  product_video.txt\r\n"
     ]
    }
   ],
   "source": [
    "# View the contents of the working directory\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Pull the transcript text and the corrected text into strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# Strip out timestamps and paste the text into \n",
    "# one, long, lowercase string with no punctuation\n",
    "def stringFromTranscript( filename ):\n",
    "    with open( filename ) as file:\n",
    "        lines_arr = file.readlines()\n",
    "    #print( lines_arr )\n",
    "    txt = \"\"\n",
    "    for line in lines_arr:\n",
    "        if re.match( r\"\\S+\", line ) and not re.match( r\"^\\d{2}\\:\\d{2}\\:\\d{2}\", line ):\n",
    "            txt += line.strip().lower() + \" \"\n",
    "    txt = re.sub( r\"\\s*\\%hesitation\\s*\", \" \", txt )\n",
    "    punc_symbols = punc_symbols = re.sub( r\"\\-\", \"\", string.punctuation )\n",
    "    regex1 = re.compile( \"\\s+[\" + re.escape( punc_symbols ) + \"]\" )\n",
    "    regex2 = re.compile( \"[\" + re.escape( punc_symbols ) + \"]\\s+\" )\n",
    "    regex3 = re.compile( \"[\" + re.escape( punc_symbols ) + \"]\" )\n",
    "    txt = regex1.sub( \" \", txt )\n",
    "    txt = regex2.sub( \" \", txt )\n",
    "    txt = regex3.sub( \"\", txt )\n",
    "    txt = re.sub( r\"\\s+\", \" \", txt )\n",
    "    txt = re.sub( r\"^\\s+\", \"\", txt )\n",
    "    txt = re.sub( r\"\\s+$\", \"\", txt )\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech to text output:\n",
      "\n",
      "this video shows you how to create a watson studio project from the home page you can create a project projects are way to organize resources for specific data science task or goal rajit includes data collaborators notebooks models and so one all to support finding insights for a well defined and fairly narrow goal for example how weather affects s \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "transcript_txt = stringFromTranscript( transcript_filename );\n",
    "print( \"Speech to text output:\\n\" )\n",
    "print( transcript_txt[0:350], \"\\n...\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected transcript:\n",
      "\n",
      "this video shows you how to create a watson studio project from the home page you can create a project projects are a way to organize resources for a specific data science task or goal a project includes data collaborators notebooks models and so on all to support finding insights for a well-defined and fairly narrow goal for example how weather af \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "corrected_txt = stringFromTranscript( corrected_filename );\n",
    "print( \"Corrected transcript:\\n\" )\n",
    "print( corrected_txt[0:350], \"\\n...\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Compare the original transcript with the corrected one\n",
    "\n",
    "This step uses the library [`difflib`](https://docs.python.org/3/library/difflib.html) to find words removed, replace, and added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "  projects\n",
      "  are\n",
      "+ a\n",
      "  way\n",
      "  to\n",
      "  organize\n",
      "  resources\n",
      "  for\n",
      "+ a\n",
      "  specific\n",
      "  data\n",
      "  science\n",
      "  task\n",
      "  or\n",
      "  goal\n",
      "- rajit\n",
      "+ a\n",
      "+ project\n",
      "  includes\n",
      "  data\n",
      "  collaborators\n",
      "  notebooks\n",
      "  models\n",
      "  and\n",
      "  so\n",
      "- one\n",
      "?   -\n",
      "\n",
      "+ on\n",
      "  all\n",
      "  to\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "\n",
    "d = difflib.Differ()\n",
    "diff = d.compare( transcript_txt.split(), corrected_txt.split() )\n",
    "\n",
    "# In the output below:\n",
    "# - Words with a \"+\" preceeding them were added in the corrections\n",
    "# - Words with a \"-\" preceeding them were removed in the corrections\n",
    "# - Words with a \"?\" preceedings them can be ignored in our case\n",
    "# See the description: https://docs.python.org/3/library/difflib.html#difflib.Differ\n",
    "print ( \"...\" )\n",
    "print( \"\\n\".join( list( diff )[20:50] ) )\n",
    "print( \"...\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a helper function to visually display the differences\n",
    "def htmlDiff( transcript_txt, corrected_txt ):\n",
    "    d = difflib.Differ()\n",
    "    diff = d.compare( transcript_txt.split(), corrected_txt.split())\n",
    "    html = \"\"\n",
    "    for word in list( diff ):\n",
    "        if re.match( r\"^\\- \", word ):\n",
    "            html += \"<span style='color: red;'>\" + re.sub( r\"^\\-\\s+\", \"\", word ) + \"</span>\" + \" \"\n",
    "        elif re.match( r\"^\\+ \", word ):\n",
    "            html += \"<span style='color: green;'>\" + re.sub( r\"\\+\\s+\", \"\", word ) + \"</span>\" + \" \"\n",
    "        elif re.match( r\"^\\? \", word ):\n",
    "            html += \" \" + \" \"\n",
    "        else:\n",
    "            html += word + \" \"\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "...<br/>  projects   are <span style='color: green;'>a</span>   way   to   organize   resources   for <span style='color: green;'>a</span>   specific   data   science   task   or   goal <span style='color: red;'>rajit</span> <span style='color: green;'>a</span> <span style='color: green;'>project</span>   includes   data   collaborators   notebooks   models   and   so <span style='color: red;'>one</span>   <span style='color: green;'>on</span>   all   to   support   finding   insights   for   a <span style='color: green;'>well-defined</span> <span style='color: red;'>well</span> <span style='color: red;'>defined</span>   and   fairly   narrow   goal   for   example   how   weather   affects   sales   in   the   companys   retail   shops   in   this   video   youll   see   how   to   create   an   empty   project <span style='color: red;'>and</span>   <span style='color: green;'>an</span>   imported   project   from   a   file <span style='color: red;'>into</span> <span style='color: green;'>and</span> <span style='color: green;'>a</span>   project   based   on   a   sample   first   to   create   an   empty   project   just   provide   a   name   for   the   project   and   give   it   a   description   by   default   the   project   will   be   restricted   in   who   can   be   added   as   a   collaborator   so   youll   be   able   to   invite   anyone   in   your   company   or   just   members   of   your   ibm   cloud   account   depending   on   whether   or   not   your   company   has <span style='color: red;'>salmon</span> <span style='color: green;'>saml</span> <span style='color: red;'>federations</span>   <span style='color: green;'>federation</span>   set   up  <br/>..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In the output below:\n",
    "# - Words in red were removed \n",
    "from IPython.core.display import display, HTML\n",
    "html = htmlDiff( transcript_txt, corrected_txt )\n",
    "display( HTML( \"...<br/>\" + html[143:1840] + \"<br/>...\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "...<br/>  lastly   you   can   connect   this   project   to   a <span style='color: green;'>github</span> <span style='color: red;'>get</span> <span style='color: red;'>hub</span>   repository   to   be   able   to   upload   content <span style='color: red;'>to</span> <span style='color: red;'>their</span>   <span style='color: green;'>there</span>     or   to   your   figure   eight   or <span style='color: green;'>definedcrowd</span> <span style='color: red;'>define</span> <span style='color: red;'>crowd</span>   account   to   create   annotation   jobs   now   lets   go   back   to   the   home   screen   create   a   project   again   and   select   the   option   to   create   a   project   from   a   sample   or   file   this   time   the   project   will   be   based   on <span style='color: red;'>the</span> <span style='color: green;'>a</span>   sample   hover   over   each   sample   to   see   a   description   in   this   case <span style='color: red;'>selected</span>   <span style='color: green;'>select</span>   the <span style='color: red;'>predicted</span>   <span style='color: green;'>predict</span>   buying   behavior   with   ml   sample   the   project   name   and   description   are   filled   in   for   you   so   just   click   create   when   its   done   view   the   new   project   on   the   assets   tab   youll   see   the   assets   included   with   this   sample   project   now   youre   ready   to   examine   the   sample   assets   and   get   started   analyzing   data   find   more   videos   in   the   cloud <span style='color: red;'>pack</span>   <span style='color: green;'>pak</span>   for   data   as   a   service   documentation <br/>..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( HTML( \"...<br/>\" + html[5573:] + \"<br/>...\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Generate dictionary files for customizing Watson Speech to Text\n",
    "\n",
    "The transcript above was generated by Watson Speech to Text, using the built-in model: \"en-US_BroadbandModel\".\n",
    "\n",
    "In our projects, we customized the language model in our Watson Speech to Text service to recognize our domain-specific jargon.  We did this by creating dictionaries of custom words:\n",
    "1. Programmatically compare the original transcript with the manually corrected transcript using diff\n",
    "2. Use the words added to generate an initial custom words dictionary\n",
    "3. Manually correct and refine the custom words dictionary\n",
    "4. Use the Watson Speech to Text API to add the custom words dictionary\n",
    "\n",
    "Steps 1. and 2. are shown below.\n",
    "\n",
    "See also:\n",
    "- [Understanding customization](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-customization)\n",
    "- [Creating a custom language model](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-languageCreate)\n",
    "- [Add words to the custom language model](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-languageCreate#addWords)\n",
    "- [API: Add custom words](https://cloud.ibm.com/apidocs/speech-to-text#addwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a helper function to generate the initial custom words dictionary\n",
    "\n",
    "def listAdditions( transcript_txt, corrected_txt ):\n",
    "    d = difflib.Differ()\n",
    "    diff = d.compare( transcript_txt.split(), corrected_txt.split())\n",
    "    added_words = []\n",
    "    txt = \"\"\n",
    "    for word in list( diff ):\n",
    "        if re.match( r\"^\\+\", word ):\n",
    "            txt += word[1:]\n",
    "        elif re.search( r\"\\S\", txt ):\n",
    "            txt = re.sub( r\"^\\s*\", \"\", txt )\n",
    "            if txt not in added_words:\n",
    "                added_words.append( txt )\n",
    "            txt = \"\"\n",
    "    added_words.sort()\n",
    "    return added_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'a project',\n",
       " 'an',\n",
       " 'and',\n",
       " 'and a',\n",
       " 'definedcrowd',\n",
       " 'federation',\n",
       " 'github',\n",
       " 'on',\n",
       " 'or',\n",
       " 'pak',\n",
       " 'predict',\n",
       " 'readme',\n",
       " 'saml',\n",
       " 'select',\n",
       " 'so on',\n",
       " 'then create',\n",
       " 'there',\n",
       " 'well-defined',\n",
       " 'zipped']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added_words = listAdditions( transcript_txt, corrected_txt )\n",
    "added_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom words dictionaries are in this form:\n",
    "```\n",
    "[\n",
    "   { word : \"IBM-Cloud\", sounds_like : [ \"I. B. M. Cloud\" ],     display_as : \"IBM Cloud\" },\n",
    "   { word : \"README\",    sounds_like : [ \"read me\" ],            display_as : \"README\" },\n",
    "   { word : \"GitHub\",    sounds_like : [ \"git hub\", \"get hub\" ], display_as : \"GitHub\" },\n",
    "   ...\n",
    "]\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `word` is an id for the custom word (ids cannot contain spaces)\n",
    "- `sounds_like` provides one or more phonetically written pronounciations\n",
    "- `display_as` is how you want the custom word to be written in the transcript (including capitalization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Helper function to generate inital dictionary, ready for manual refinement\n",
    "def genDictionary( added_words ):\n",
    "    custom_words = []\n",
    "    for term in added_words:\n",
    "        custom_words.append( { \"word\" : term, \"sounds_like\" : [ term ], \"display_as\" : term } )\n",
    "    return custom_words  \n",
    "\n",
    "# Helper function to view dictionary\n",
    "def prettyPrintDictionary( custom_words ):\n",
    "    str = \"[\\n\"\n",
    "    for entry in custom_words:\n",
    "        word = \"word: '\" + entry[\"word\"] + \"'\" + \" \"*( 13 - len( entry[\"word\"] ) )\n",
    "        sounds_like = \"sounds_like: [ '\" + entry[\"sounds_like\"][0] + \"' ]\" + \" \"*( 13 - len( entry[\"sounds_like\"][0] ) )\n",
    "        display_as = \"display_as: '\" + entry[\"display_as\"] + \"'\" + \" \"*( 13 - len( entry[\"display_as\"] ) )\n",
    "        str += \"   { \" + word + sounds_like + display_as + \" },\\n\"\n",
    "    str = re.sub( r\"\\s*,$\", \"\", str )\n",
    "    str += \"]\"\n",
    "    print( str )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "   { word: 'a'            sounds_like: [ 'a' ]            display_as: 'a'             },\n",
      "   { word: 'a project'    sounds_like: [ 'a project' ]    display_as: 'a project'     },\n",
      "   { word: 'an'           sounds_like: [ 'an' ]           display_as: 'an'            },\n",
      "   { word: 'and'          sounds_like: [ 'and' ]          display_as: 'and'           },\n",
      "   { word: 'and a'        sounds_like: [ 'and a' ]        display_as: 'and a'         },\n",
      "   { word: 'definedcrowd' sounds_like: [ 'definedcrowd' ] display_as: 'definedcrowd'  },\n",
      "   { word: 'federation'   sounds_like: [ 'federation' ]   display_as: 'federation'    },\n",
      "   { word: 'github'       sounds_like: [ 'github' ]       display_as: 'github'        },\n",
      "   { word: 'on'           sounds_like: [ 'on' ]           display_as: 'on'            },\n",
      "   { word: 'or'           sounds_like: [ 'or' ]           display_as: 'or'            },\n",
      "   { word: 'pak'          sounds_like: [ 'pak' ]          display_as: 'pak'           },\n",
      "   { word: 'predict'      sounds_like: [ 'predict' ]      display_as: 'predict'       },\n",
      "   { word: 'readme'       sounds_like: [ 'readme' ]       display_as: 'readme'        },\n",
      "   { word: 'saml'         sounds_like: [ 'saml' ]         display_as: 'saml'          },\n",
      "   { word: 'select'       sounds_like: [ 'select' ]       display_as: 'select'        },\n",
      "   { word: 'so on'        sounds_like: [ 'so on' ]        display_as: 'so on'         },\n",
      "   { word: 'then create'  sounds_like: [ 'then create' ]  display_as: 'then create'   },\n",
      "   { word: 'there'        sounds_like: [ 'there' ]        display_as: 'there'         },\n",
      "   { word: 'well-defined' sounds_like: [ 'well-defined' ] display_as: 'well-defined'  },\n",
      "   { word: 'zipped'       sounds_like: [ 'zipped' ]       display_as: 'zipped'        }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "custom_words = genDictionary( added_words )\n",
    "prettyPrintDictionary( custom_words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
